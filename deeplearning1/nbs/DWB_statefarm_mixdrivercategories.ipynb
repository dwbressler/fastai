{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fastai/deeplearning1/nbs\n"
     ]
    }
   ],
   "source": [
    "cd /home/ubuntu/fastai/deeplearning1/nbs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os, json, shutil\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "import utils; reload(utils)\n",
    "from utils import plots\n",
    "from utils import *\n",
    "from vgg16 import Vgg16\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data\n"
     ]
    }
   ],
   "source": [
    "cd /home/ubuntu/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir statefarm_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/statefarm_mix\n"
     ]
    }
   ],
   "source": [
    "cd statefarm_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new HTTPS connection (1): www.kaggle.com\n",
      "downloading https://www.kaggle.com/c/state-farm-distracted-driver-detection/download/sample_submission.csv.zip\n",
      "\n",
      "Starting new HTTPS connection (1): storage.googleapis.com\n",
      "sample_submission.csv.zip 100% |#####################| Time: 0:00:01 144.9 KiB/s\n",
      "\n",
      "downloading https://www.kaggle.com/c/state-farm-distracted-driver-detection/download/imgs.zip\n",
      "\n",
      "imgs.zip 100% |######################################| Time: 0:06:46  10.1 MiB/s\n",
      "\n",
      "downloading https://www.kaggle.com/c/state-farm-distracted-driver-detection/download/driver_imgs_list.csv.zip\n",
      "\n",
      "Resetting dropped connection: www.kaggle.com\n",
      "driver_imgs_list.csv.zip 100% |######################| Time: 0:00:00 104.0 KiB/s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!kg download -u superexistential -p XXXXXX -c state-farm-distracted-driver-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/statefarm_mix\n"
     ]
    }
   ],
   "source": [
    "path='/home/ubuntu/data/statefarm_mix/'\n",
    "%cd $path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!unzip -q imgs.zip\n",
    "!unzip -q driver_imgs_list.csv.zip\n",
    "!rm imgs.zip\n",
    "!rm driver_imgs_list.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir sample\n",
    "!mkdir valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.mkdir(path+'sample/train')\n",
    "os.mkdir(path+'sample/valid')\n",
    "os.mkdir(path+'test/unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10): os.mkdir(path+'sample/train/c'+str(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10): os.mkdir(path+'sample/valid/c'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10): os.mkdir(path+'valid/c'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/statefarm_mix/test\n"
     ]
    }
   ],
   "source": [
    "%cd $path/test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mv *.jpg ./unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/statefarm_mix/train/c0\n",
      "/home/ubuntu/data/statefarm_mix/train/c1\n",
      "/home/ubuntu/data/statefarm_mix/train/c2\n",
      "/home/ubuntu/data/statefarm_mix/train/c3\n",
      "/home/ubuntu/data/statefarm_mix/train/c4\n",
      "/home/ubuntu/data/statefarm_mix/train/c5\n",
      "/home/ubuntu/data/statefarm_mix/train/c6\n",
      "/home/ubuntu/data/statefarm_mix/train/c7\n",
      "/home/ubuntu/data/statefarm_mix/train/c8\n",
      "/home/ubuntu/data/statefarm_mix/train/c9\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    nupath=path+'train/c' + str(i)\n",
    "    %cd $nupath\n",
    "    g=glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for j in range(100):\n",
    "        shutil.copy(shuf[j], path+'sample/train/c'+str(i)+'/'+shuf[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#open driver imgs list csv\n",
    "drivimgcsvpath='/home/ubuntu/data/statefarm/driver_imgs_list.csv'\n",
    "df=pd.read_csv(drivimgcsvpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p002</th>\n",
       "      <td>725</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p012</th>\n",
       "      <td>823</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p014</th>\n",
       "      <td>876</td>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p015</th>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p016</th>\n",
       "      <td>1078</td>\n",
       "      <td>1078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p021</th>\n",
       "      <td>1237</td>\n",
       "      <td>1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p022</th>\n",
       "      <td>1233</td>\n",
       "      <td>1233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p024</th>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p026</th>\n",
       "      <td>1196</td>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p035</th>\n",
       "      <td>848</td>\n",
       "      <td>848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p039</th>\n",
       "      <td>651</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p041</th>\n",
       "      <td>605</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p042</th>\n",
       "      <td>591</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p045</th>\n",
       "      <td>724</td>\n",
       "      <td>724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p047</th>\n",
       "      <td>835</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p049</th>\n",
       "      <td>1011</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p050</th>\n",
       "      <td>790</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p051</th>\n",
       "      <td>920</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p052</th>\n",
       "      <td>740</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p056</th>\n",
       "      <td>794</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p061</th>\n",
       "      <td>809</td>\n",
       "      <td>809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p064</th>\n",
       "      <td>820</td>\n",
       "      <td>820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p066</th>\n",
       "      <td>1034</td>\n",
       "      <td>1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p072</th>\n",
       "      <td>346</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p075</th>\n",
       "      <td>814</td>\n",
       "      <td>814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p081</th>\n",
       "      <td>823</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         classname   img\n",
       "subject                 \n",
       "p002           725   725\n",
       "p012           823   823\n",
       "p014           876   876\n",
       "p015           875   875\n",
       "p016          1078  1078\n",
       "p021          1237  1237\n",
       "p022          1233  1233\n",
       "p024          1226  1226\n",
       "p026          1196  1196\n",
       "p035           848   848\n",
       "p039           651   651\n",
       "p041           605   605\n",
       "p042           591   591\n",
       "p045           724   724\n",
       "p047           835   835\n",
       "p049          1011  1011\n",
       "p050           790   790\n",
       "p051           920   920\n",
       "p052           740   740\n",
       "p056           794   794\n",
       "p061           809   809\n",
       "p064           820   820\n",
       "p066          1034  1034\n",
       "p072           346   346\n",
       "p075           814   814\n",
       "p081           823   823"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subjs=df.groupby('subject').count().index\n",
    "subj_num=all_subjs.shape[0]\n",
    "df.groupby('subject').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p021'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j=0\n",
    "use_these_subj=np.random.permutation(26)[:5]\n",
    "#all_subjs[use_these_subj]\n",
    "all_subjs[use_these_subj[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/statefarm_mix/train/c0\n",
      "/home/ubuntu/data/statefarm_mix/train/c1\n",
      "/home/ubuntu/data/statefarm_mix/train/c2\n",
      "/home/ubuntu/data/statefarm_mix/train/c3\n",
      "/home/ubuntu/data/statefarm_mix/train/c4\n",
      "/home/ubuntu/data/statefarm_mix/train/c5\n",
      "/home/ubuntu/data/statefarm_mix/train/c6\n",
      "/home/ubuntu/data/statefarm_mix/train/c7\n",
      "/home/ubuntu/data/statefarm_mix/train/c8\n",
      "/home/ubuntu/data/statefarm_mix/train/c9\n"
     ]
    }
   ],
   "source": [
    "#use_these_subjs=['p072','p042','p041','p039','p045','p002']\n",
    "# move just the right subjects into the validation folders\n",
    "for i in range(10):\n",
    "    nupath=path+'train/c' + str(i)\n",
    "    %cd $nupath\n",
    "    use_these_subj=np.random.permutation(26)[:5]\n",
    "    for j in range(5):\n",
    "    #shuf = np.random.permutation(g)\n",
    "        imglist=df[(df['subject'].str.contains(all_subjs[use_these_subj[j]]))&(df['classname'].str.contains('c'+str(i)))][['img']]\n",
    "        for k in range(np.shape(imglist)[0]):\n",
    "            os.rename(imglist.iloc[[k][0]][0], path+'valid/c'+str(i)+'/'+imglist.iloc[[k][0]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/statefarm_mix/valid/c0\n",
      "/home/ubuntu/data/statefarm_mix/valid/c1\n",
      "/home/ubuntu/data/statefarm_mix/valid/c2\n",
      "/home/ubuntu/data/statefarm_mix/valid/c3\n",
      "/home/ubuntu/data/statefarm_mix/valid/c4\n",
      "/home/ubuntu/data/statefarm_mix/valid/c5\n",
      "/home/ubuntu/data/statefarm_mix/valid/c6\n",
      "/home/ubuntu/data/statefarm_mix/valid/c7\n",
      "/home/ubuntu/data/statefarm_mix/valid/c8\n",
      "/home/ubuntu/data/statefarm_mix/valid/c9\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    nupath=path+'valid/c' + str(i)\n",
    "    %cd $nupath\n",
    "    g=glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for j in range(25):\n",
    "        shutil.copy(shuf[j], path+'sample/valid/c'+str(i)+'/'+shuf[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run analysis (just fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fastai/deeplearning1/nbs\n"
     ]
    }
   ],
   "source": [
    "cd /home/ubuntu/fastai/deeplearning1/nbs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, json, shutil\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "import utils; reload(utils)\n",
    "from utils import plots\n",
    "from utils import *\n",
    "from vgg16 import Vgg16\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_HOME_DIR = '/home/ubuntu/data/statefarm_mix'\n",
    "path = DATA_HOME_DIR + '/' #'/sample/'\n",
    "test_path = DATA_HOME_DIR + '/test/' #We use all the test data\n",
    "results_path=DATA_HOME_DIR + '/results/'\n",
    "train_path=path + '/train/'\n",
    "valid_path=path + '/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18334 images belonging to 10 classes.\n",
      "Found 4090 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = vgg.get_batches(path+'train', batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(path+'valid', batch_size=batch_size*2, shuffle=False)\n",
    "vgg.finetune(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "18334/18334 [==============================] - 608s - loss: 1.8742 - acc: 0.4788 - val_loss: 2.1203 - val_acc: 0.3247\n"
     ]
    }
   ],
   "source": [
    "vgg.fit(batches, val_batches, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg.model.save_weights(path+'results/ft1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# precomputing data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fastai/deeplearning1/nbs\n"
     ]
    }
   ],
   "source": [
    "cd /home/ubuntu/fastai/deeplearning1/nbs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, json, shutil\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "import utils; reload(utils)\n",
    "from utils import plots\n",
    "from utils import *\n",
    "from vgg16 import Vgg16\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_HOME_DIR = '/home/ubuntu/data/statefarm_mix'\n",
    "path = DATA_HOME_DIR + '/' #'/sample/'\n",
    "test_path = DATA_HOME_DIR + '/test/' #We use all the test data\n",
    "results_path=DATA_HOME_DIR + '/results/'\n",
    "train_path=path + '/train/'\n",
    "valid_path=path + '/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18334 images belonging to 10 classes.\n",
      "Found 4090 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "vgg = Vgg16()\n",
    "vgg.model.load_weights(path+'results/ft1.h5') \n",
    "batches = vgg.get_batches(path+'train', shuffle=False, batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(path+'valid', shuffle=False, batch_size=batch_size)\n",
    "test_batches = vgg.get_batches(path+'test', shuffle=False, batch_size=batch_size)\n",
    "\n",
    "val_classes = val_batches.classes\n",
    "trn_classes = batches.classes\n",
    "val_labels = onehot(val_classes)\n",
    "trn_labels = onehot(trn_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = vgg.model.layers\n",
    "last_conv_idx = [index for index,layer in enumerate(layers) \n",
    "                     if type(layer) is Convolution2D][-1]\n",
    "conv_layers = layers[:last_conv_idx+3]\n",
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4090 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "val_batches = vgg.get_batches(path+'valid', shuffle=False, batch_size=batch_size)\n",
    "val_features = conv_model.predict_generator(val_batches, val_batches.nb_sample)\n",
    "save_array(path + 'valid_convlayer_features2.bc', val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18334 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = vgg.get_batches(path+'train', shuffle=False, batch_size=batch_size)\n",
    "trn_features = conv_model.predict_generator(batches, batches.nb_sample)\n",
    "save_array(path + 'train_convlayer_features2.bc', trn_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18334 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# create 5x as many training samples as we currently have through data augmentation!\n",
    "\n",
    "gen_t = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05, \n",
    "                shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "da_batches = get_batches(path+'train', gen_t, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "da_conv_feat = conv_model.predict_generator(da_batches, da_batches.nb_sample*5)\n",
    "save_array(path + 'train_da_convlayer_features.bc', da_conv_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combine the new da-images with the original training data\n",
    "da_conv_feat = np.concatenate([da_conv_feat, trn_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#update the training labels wo they're 6x as long\n",
    "da_trn_labels = np.concatenate([trn_labels]*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_the_model():\n",
    "    model = Sequential([\n",
    "        #MaxPooling2D(input_shape=np.shape(trn_features)[1:]),\n",
    "        #Flatten(),\n",
    "        BatchNormalization(input_shape=np.shape(trn_features)[1:]),\n",
    "        Dropout(.8),\n",
    "        Dense(4096, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.8),\n",
    "        Dense(4096, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.8),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    #for layera in range(np.shape(fc_layers)[0]):\n",
    "    #    model.layers[layera].set_weights(fc_layers[layera].get_weights())\n",
    "    # Such a finely tuned model needs to be updated very slowly!\n",
    "    #opt = RMSprop(lr=0.00001, rho=0.7)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=get_the_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18334 samples, validate on 4090 samples\n",
      "Epoch 1/1\n",
      "18334/18334 [==============================] - 35s - loss: 0.0911 - acc: 0.9768 - val_loss: 3.9804 - val_acc: 0.4531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbbea2eba50>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn_features, trn_labels, nb_epoch=1, \n",
    "             batch_size=batch_size, validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18334 samples, validate on 4090 samples\n",
      "Epoch 1/1\n",
      "18334/18334 [==============================] - 35s - loss: 0.0735 - acc: 0.9829 - val_loss: 4.4198 - val_acc: 0.4672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbbea2ebd10>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn_features, trn_labels, nb_epoch=1, \n",
    "             batch_size=batch_size, validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18334 samples, validate on 4090 samples\n",
      "Epoch 1/1\n",
      "18334/18334 [==============================] - 35s - loss: 0.0552 - acc: 0.9889 - val_loss: 5.1494 - val_acc: 0.4152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbbea2ebb90>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn_features, trn_labels, nb_epoch=1, \n",
    "             batch_size=batch_size, validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(path+'results/base1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen=image.ImageDataGenerator()\n",
    "test_batches=gen.flow_from_directory(test_path, target_size=(224,224),\n",
    "                class_mode='categorical', shuffle=False, batch_size=batch_size)\n",
    "test_features = load_array('/home/ubuntu/data/statefarm/test_convlayer_features.bc')\n",
    "preds=model.predict(test_features,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_clipped = preds.clip(min=0.02, max=0.98)\n",
    "filenames = test_batches.filenames\n",
    "ids=([f[f.find('/')+1:] for f in filenames])\n",
    "ids_array=np.array(ids)\n",
    "subm=np.concatenate((ids_array[:,None],preds_clipped), axis=1)\n",
    "%cd $DATA_HOME_DIR\n",
    "submission_file_name = 'statefarm_mix_submission1.csv'\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(subm,columns='img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9'.split(','))\n",
    "df.to_csv(submission_file_name,index=False)\n",
    "from IPython.display import FileLink\n",
    "%cd /home/ubuntu/fastai/deeplearning1/nbs/\n",
    "df.to_csv(submission_file_name,index=False)\n",
    "FileLink(submission_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=get_the_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 110004 samples, validate on 4090 samples\n",
      "Epoch 1/1\n",
      "110004/110004 [==============================] - 211s - loss: 0.4516 - acc: 0.9086 - val_loss: 3.2094 - val_acc: 0.5826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbbe7c37590>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(da_conv_feat, da_trn_labels, nb_epoch=1, \n",
    "             batch_size=batch_size, validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 110004 samples, validate on 4090 samples\n",
      "Epoch 1/1\n",
      "110004/110004 [==============================] - 211s - loss: 0.2100 - acc: 0.9639 - val_loss: 5.0243 - val_acc: 0.5538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbbea2ebb10>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(da_conv_feat, da_trn_labels, nb_epoch=1, \n",
    "             batch_size=batch_size, validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(path+'results/da1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pseudolabeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we first need to get our model's final predictions for the validation data\n",
    "val_pseudo = model.predict(val_features, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# then, combine these predictions with our actual training labels\n",
    "comb_pseudo = np.concatenate([da_trn_labels, val_pseudo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#then, combine the input features of the validation data with our training input features\n",
    "comb_feat = np.concatenate([da_conv_feat, val_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(comb_feat, comb_pseudo, batch_size=batch_size, nb_epoch=1, \n",
    "             validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
